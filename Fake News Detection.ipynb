{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33ea6c9e",
   "metadata": {},
   "source": [
    "# DETECTING FAKE NEWS WITH PYTHON AND MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe7b52d",
   "metadata": {},
   "source": [
    "## What is Fake News?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b94c0",
   "metadata": {},
   "source": [
    "The internet and social media have made it very easy for anyone to publish content on a website, blog or social media profile and potentially reach large audiences. With so many people now getting news from social media sites, many content creators/publishers have used this to their advantage. Lots of things we read online especially in your social media feeds may appear to be true, often is not.\\\n",
    "**False news are stories or hoaxes created to deliberately misinform or deceive readers.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929ac99e",
   "metadata": {},
   "source": [
    " ## What if TfidfVectorizer ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f45aec4",
   "metadata": {},
   "source": [
    "**TF (Term Frequency):** The number of times a word appears in a document is its Term Frequency. A higher value means a term appears more often than others, and so, the document is a good match when the term is part of the search terms.\n",
    "\n",
    "**IDF (Inverse Document Frequency):** Words that occur many times a document, but also occur many times in many others, may be irrelevant. IDF is a measure of how significant a term is in the entire corpus.\n",
    "\n",
    "The TfidfVectorizer converts a collection of raw documents into a matrix of TF-IDF features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a084b5",
   "metadata": {},
   "source": [
    "## What is Passive-Aggressive Classifier ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1ca488",
   "metadata": {},
   "source": [
    "Passive Aggressive algorithms are online learning algorithms. Such an algorithm remains passive for a correct classification outcome, and turns aggressive in the event of a miscalculation, updating and adjusting. Unlike most other algorithms, it does not converge. Its purpose is to make updates that correct the loss, causing very little change in the norm of the weight vector. These are generally used for large-scale learning. In this the input data comes in sequential order and the machine learning model is updated step-by-step, as opposed to batch learning, where the entire training dataset is used at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fade51",
   "metadata": {},
   "source": [
    "## Detecting Fake News with Python "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdb3fb3",
   "metadata": {},
   "source": [
    "To build a model using Passive-Aggressive Classifier to accurately classifies pieces of news as Real and Fake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081281cd",
   "metadata": {},
   "source": [
    "## The Fake News Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bef0cd",
   "metadata": {},
   "source": [
    "The dataset used in this project has a shape of 7796×4. The first column identifies the news, the second and third are the title and text, and the fourth column has labels denoting whether the news is REAL or FAKE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9cb450",
   "metadata": {},
   "source": [
    "## Steps for detecting fake news:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14539716",
   "metadata": {},
   "source": [
    "**1. Importing necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33d9d48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries to be used\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f77c1",
   "metadata": {},
   "source": [
    "**2. Reading data into dataframe and getting shape of dataset , first 5 records and labels from dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30c18a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6335, 4)\n",
      "   Unnamed: 0                                              title  \\\n",
      "0        8476                       You Can Smell Hillary’s Fear   \n",
      "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
      "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
      "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
      "4         875   The Battle of New York: Why This Primary Matters   \n",
      "\n",
      "                                                text label  \n",
      "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
      "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
      "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
      "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
      "4  It's primary day in New York and front-runners...  REAL  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    FAKE\n",
       "1    FAKE\n",
       "2    REAL\n",
       "3    FAKE\n",
       "4    REAL\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the inputs \n",
    "filpath= \"C:/Users/HP/Desktop/news.csv\"\n",
    "df=pd.read_csv(filpath)\n",
    "\n",
    "# Print shape and head('First Five Examples')\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# Get the labels\n",
    "labels=df.label\n",
    "labels.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5ffa56",
   "metadata": {},
   "source": [
    "**3. Splitting the dataset into training and testing sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "310e6aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6237    The head of a leading survivalist group has ma...\n",
       " 3722    ‹ › Arnaldo Rodgers is a trained and educated ...\n",
       " 5774    Patty Sanchez, 51, used to eat 13,000 calories...\n",
       " 336     But Benjamin Netanyahu’s reelection was regard...\n",
       " 3622    John Kasich was killing it with these Iowa vot...\n",
       "                               ...                        \n",
       " 5699                                                     \n",
       " 2550    It’s not that Americans won’t elect wealthy pr...\n",
       " 537     Anyone writing sentences like ‘nevertheless fu...\n",
       " 1220    More Catholics are in Congress than ever befor...\n",
       " 4271    It was hosted by CNN, and the presentation was...\n",
       " Name: text, Length: 5068, dtype: object,\n",
       " 3534    A day after the candidates squared off in a fi...\n",
       " 6265    VIDEO : FBI SOURCES SAY INDICTMENT LIKELY FOR ...\n",
       " 3123    It's debate season, where social media has bro...\n",
       " 3940    Mitch McConnell has decided to wager the Repub...\n",
       " 2856    Donald Trump, the actual Republican candidate ...\n",
       "                               ...                        \n",
       " 4986    Washington (CNN) President Barack Obama announ...\n",
       " 5789    The revival of middle-class jobs has been one ...\n",
       " 4338    \"I can guarantee that,\" Obama answered when as...\n",
       " 5924    Videos 30 Civilians Die In US Airstrike Called...\n",
       " 6030    The retired neurosurgeon lashed out Friday mor...\n",
       " Name: text, Length: 1267, dtype: object,\n",
       " 6237    FAKE\n",
       " 3722    FAKE\n",
       " 5774    FAKE\n",
       " 336     REAL\n",
       " 3622    REAL\n",
       "         ... \n",
       " 5699    FAKE\n",
       " 2550    REAL\n",
       " 537     REAL\n",
       " 1220    REAL\n",
       " 4271    REAL\n",
       " Name: label, Length: 5068, dtype: object,\n",
       " 3534    REAL\n",
       " 6265    FAKE\n",
       " 3123    REAL\n",
       " 3940    REAL\n",
       " 2856    REAL\n",
       "         ... \n",
       " 4986    REAL\n",
       " 5789    REAL\n",
       " 4338    REAL\n",
       " 5924    FAKE\n",
       " 6030    REAL\n",
       " Name: label, Length: 1267, dtype: object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the dataset\n",
    "x_train,x_test,y_train,y_test=train_test_split(df['text'], labels, test_size=0.2, random_state=7)\n",
    "x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9635836",
   "metadata": {},
   "source": [
    "Initializing TfidfVectorizer with stop words from the English language and a maximum document frequency of 0.7 (terms with a higher document frequency will be discarded). Stop words are the most common words in a language that are to be filtered out before processing the natural language data. And a TfidfVectorizer turns a collection of raw documents into a matrix of TF-IDF features.\\\n",
    "\\\n",
    "**4. Now let's fit and transform the vectorizer on the train set, and transform the vectorizer on the test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb5e937e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<2x61651 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 271 stored elements in Compressed Sparse Row format>,\n",
       " <2x61651 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 247 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create TfIdf Vector\n",
    "tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "\n",
    "# Transforming train and test set to TfIdf vectors\n",
    "TfIdf_train = tfidf_vectorizer.fit_transform(x_train)\n",
    "TfIdf_test = tfidf_vectorizer.transform(x_test)\n",
    "TfIdf_train[0:2],TfIdf_test[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ba2f1",
   "metadata": {},
   "source": [
    "**5. Next, we’ll initialize a PassiveAggressiveClassifier. We’ll fit this on tfidf_train and y_train.**\n",
    "\n",
    "Then, we’ll predict on the test set from the TfidfVectorizer and calculate the accuracy with accuracy_score() from sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b074f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model:- 0.9234411996842936\n"
     ]
    }
   ],
   "source": [
    "# Creating passive agressive classifier\n",
    "model = PassiveAggressiveClassifier(max_iter=50)\n",
    "model.fit(TfIdf_train,y_train)\n",
    "\n",
    "# Predicting on Test set and calculating accuracy\n",
    "y_pred=model.predict(TfIdf_test)\n",
    "score=accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy of model:-\",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b308df9b",
   "metadata": {},
   "source": [
    "**Now we will do hyperparameter tuning for regularization parameter and number of iterations,by varying one hyperparameter and keeping the other constant and measuring for which value of hyperparameter the accuracy is maximum.**\n",
    "\n",
    "**6. Tuning of regularization parameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c952d66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is max for regularization:- 0.9 And it is:- 0.930544593528019\n"
     ]
    }
   ],
   "source": [
    "# Tuning regularization parameter\n",
    "\n",
    "C = [0.1,0.2,0.5,0.9,1]\n",
    "accuracy = []\n",
    "for reg in C:\n",
    "    model = PassiveAggressiveClassifier(max_iter=50 , C=reg)\n",
    "    model.fit(TfIdf_train,y_train)\n",
    "    \n",
    "    y_pred=model.predict(TfIdf_test)\n",
    "    score=accuracy_score(y_test,y_pred)\n",
    "    accuracy.append(score)\n",
    "    \n",
    "max_accuracy = max(accuracy)\n",
    "C_max = C[accuracy.index(max_accuracy)]\n",
    "\n",
    "print(\"Accuracy is max for regularization:-\" ,C_max,\"And it is:-\",max_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025b84a1",
   "metadata": {},
   "source": [
    "We got accuracy maximum for regularization parameter 0.9 with accuracy 0.930544593528019 ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc966477",
   "metadata": {},
   "source": [
    "**7. Tuning of max iterations hyperparameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4461155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\tensorflow-sessions\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:577: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is max for regularisation:- 500 and it is:- 0.9297553275453828\n"
     ]
    }
   ],
   "source": [
    "# Tuning max_iter parameter \n",
    "\n",
    "Iteration  = [10,50,100,200,500,1000]\n",
    "accuracy = []\n",
    "for epoch in Iteration:\n",
    "    model = PassiveAggressiveClassifier(max_iter=epoch , C=C_max)\n",
    "    model.fit(TfIdf_train,y_train)\n",
    "    \n",
    "    y_pred=model.predict(TfIdf_test)\n",
    "    score=accuracy_score(y_test,y_pred)\n",
    "    accuracy.append(score)\n",
    "    \n",
    "max_accuracy = max(accuracy)\n",
    "iter_max = Iteration[accuracy.index(max_accuracy)]\n",
    "accuracy\n",
    "print(\"Accuracy is max for regularisation:-\" ,iter_max,\"and it is:-\",max_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7137fc76",
   "metadata": {},
   "source": [
    "In this we got accuracy maximum for 500 iterations with accuracy of 0.9297553275453828 ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade7d2d1",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b3516e",
   "metadata": {},
   "source": [
    "**8. Now we will use the hyperpaameters value obtained during tuning and create the final model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99b0f860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9297553275453828"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final = PassiveAggressiveClassifier(max_iter=iter_max , C=C_max)\n",
    "model_final.fit(TfIdf_train,y_train)\n",
    "\n",
    "y_pred=model_final.predict(TfIdf_test)\n",
    "score_final=accuracy_score(y_test,y_pred)\n",
    "score_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bded3cff",
   "metadata": {},
   "source": [
    "**We got an accuracy of 0.929% with this model** \n",
    "\n",
    "**9. Finally, we will print out a confusion matrix to gain insight into the number of false and true negatives and positives.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e45519ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[592,  46],\n",
       "       [ 43, 586]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building Confusion Matrix\n",
    "confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355599a6",
   "metadata": {},
   "source": [
    "So with this model we have 592 true positives, 586 true negatives, 43 false positives, and 46 false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e00b8",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a154927b",
   "metadata": {},
   "source": [
    "With this project we learned to detect fake news with Python. We took a political dataset, implemented a TfidfVectorizer, initialized a PassiveAggressiveClassifier, and fit our model. We ended up obtaining an accuracy of 92.97% in magnitude.\n",
    "\n",
    "The reason for selecting this model can be understood from the problem we are dealing. We needed to detect whether the news is Real or False on a large dataset. For example in case of 'Twitter' where there are millions of comments or posts per hour, it is computationally expensive to use a batch algorithm because of the sheer size of the data. That's why we used Passive-Agressive classifier which is an online-learning algorithm where the algorithm will get a training example, update the classifier, and then throw away the example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
